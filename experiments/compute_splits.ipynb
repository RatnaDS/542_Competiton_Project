{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting into train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_utils.dataloader import Dataloader\n",
    "from data_utils.splitting import DataSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_path = os.path.join(\"..\", \"data\", \"TrainingData\")\n",
    "dataloader = Dataloader(data_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_ids = [\"001\", \"002\", \"003\", \"004\", \"005\", \"006\", \"007\", \"008\"]\n",
    "session_numbers = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the original data: This is not really necassary, but is done to\n",
    "# make the code future-proof, in case we need stratified splits.\n",
    "all_ys = []\n",
    "for subject_id in subject_ids:\n",
    "    for session_number in session_numbers:\n",
    "        try:\n",
    "            x, y = dataloader.load_and_join_data(subject_id, session_number)\n",
    "            uid = f\"{subject_id}_{session_number}\"\n",
    "            y[\"uid\"] = [uid for _ in range(len(y))]\n",
    "            all_ys.append(y)\n",
    "        except FileNotFoundError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.concat(all_ys, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = DataSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = splitter.split_ids(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['005_02',\n",
       "  '001_06',\n",
       "  '003_02',\n",
       "  '001_05',\n",
       "  '002_02',\n",
       "  '003_01',\n",
       "  '003_03',\n",
       "  '005_01',\n",
       "  '001_07',\n",
       "  '002_05',\n",
       "  '004_02',\n",
       "  '002_03',\n",
       "  '001_02',\n",
       "  '002_04',\n",
       "  '001_03',\n",
       "  '004_01'],\n",
       " 'val': ['001_08', '002_01', '001_01', '001_04'],\n",
       " 'test': ['005_03',\n",
       "  '006_01',\n",
       "  '006_02',\n",
       "  '006_03',\n",
       "  '007_01',\n",
       "  '007_02',\n",
       "  '007_03',\n",
       "  '007_04',\n",
       "  '008_01']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file for documentation\n",
    "with open(os.path.join(\"metadata\", \"split_ids.json\"), \"w\") as f:\n",
    "    json.dump(splits, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The paths to save the splits\n",
    "data_save_path = os.path.join(\"window2_data\", \"splits\")\n",
    "train_path = os.path.join(data_save_path, \"train\")\n",
    "create_path(train_path)\n",
    "val_path = os.path.join(data_save_path, \"val\")\n",
    "create_path(val_path)\n",
    "test_path = os.path.join(data_save_path, \"test\")\n",
    "create_path(test_path)\n",
    "save_paths = {\n",
    "    \"train\": train_path,\n",
    "    \"val\": val_path,\n",
    "    \"test\": test_path\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = os.path.join(\"window2_data\", \"preprocessed_data\")\n",
    "SRC_X_TEMPLATE = \"subject_{}_session_{}__x.csv\"\n",
    "SRC_Y_TEMPLATE = \"subject_{}_session_{}__y.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DST_X_TEMPLATE = \"subject_{}_session_{}__x.csv\"\n",
    "DST_Y_TEMPLATE = \"subject_{}_session_{}__y.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split, uids in splits.items():\n",
    "    savepath = save_paths[split]\n",
    "    for uid in uids:\n",
    "        subject_id, session_id = uid.split(\"_\")\n",
    "        \n",
    "        src_filename_x = os.path.join(src_path, SRC_X_TEMPLATE.format(subject_id, session_id))\n",
    "        save_filename_x = os.path.join(savepath, DST_X_TEMPLATE.format(subject_id, session_id))\n",
    "        \n",
    "        src_filename_y = os.path.join(src_path, SRC_Y_TEMPLATE.format(subject_id, session_id))\n",
    "        save_filename_y = os.path.join(savepath, DST_Y_TEMPLATE.format(subject_id, session_id))\n",
    "        \n",
    "        shutil.move(src_filename_x, save_filename_x)\n",
    "        shutil.move(src_filename_y, save_filename_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
