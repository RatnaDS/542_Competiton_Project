{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WindowSize_3sec.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "22ITlwg0FkeF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42858d65-1ba8-4997-c1cf-3594b46298da"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prIF1sjM-c3i",
        "outputId": "20230bee-064a-4a95-a703-222f2a2fc02a"
      },
      "source": [
        "!ls /content/drive/MyDrive/ProjC/Nov11_newModel/competition-project-2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " attempt-1.ipynb   experiments\t Plots.docx\t\t\t  test_data.zip\n",
            " data.zip\t   ml_utils\t'Ratna Copy of attempt-1.ipynb'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng-s1F7Z-xKL"
      },
      "source": [
        "!cp /content/drive/MyDrive/ProjC/Nov11_newModel/data.zip ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wUZq7ty_AZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bef72a81-211b-454e-81a4-1ab10ae7d024"
      },
      "source": [
        "!unzip data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "  inflating: __MACOSX/._data         \n",
            "  inflating: data/.DS_Store          \n",
            "  inflating: __MACOSX/data/._.DS_Store  \n",
            "replace data/.gitignore? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: data/.gitignore         \n",
            "  inflating: __MACOSX/data/._.gitignore  \n",
            "  inflating: data/splits/test/subject_007_session_04__y.csv  \n",
            "  inflating: data/splits/test/subject_007_session_04__x.csv  \n",
            "  inflating: data/splits/test/subject_007_session_02__x.csv  \n",
            "  inflating: data/splits/test/subject_007_session_02__y.csv  \n",
            "  inflating: data/splits/test/subject_008_session_01__y.csv  \n",
            "  inflating: data/splits/test/subject_006_session_02__x.csv  \n",
            "  inflating: data/splits/test/subject_006_session_02__y.csv  \n",
            "  inflating: data/splits/test/subject_008_session_01__x.csv  \n",
            "  inflating: data/splits/test/subject_005_session_03__y.csv  \n",
            "  inflating: data/splits/test/subject_005_session_03__x.csv  \n",
            "  inflating: data/splits/test/subject_006_session_01__y.csv  \n",
            "  inflating: data/splits/test/subject_006_session_01__x.csv  \n",
            "  inflating: data/splits/test/subject_007_session_03__y.csv  \n",
            "  inflating: data/splits/test/subject_007_session_03__x.csv  \n",
            "  inflating: data/splits/test/subject_007_session_01__y.csv  \n",
            "  inflating: data/splits/test/subject_007_session_01__x.csv  \n",
            "  inflating: data/splits/test/subject_006_session_03__y.csv  \n",
            "  inflating: data/splits/test/subject_006_session_03__x.csv  \n",
            "  inflating: data/splits/train/subject_002_session_04__y.csv  \n",
            "  inflating: data/splits/train/subject_005_session_02__x.csv  \n",
            "  inflating: data/splits/train/subject_005_session_02__y.csv  \n",
            "  inflating: data/splits/train/subject_002_session_04__x.csv  \n",
            "  inflating: data/splits/train/subject_004_session_02__x.csv  \n",
            "  inflating: data/splits/train/subject_004_session_02__y.csv  \n",
            "  inflating: data/splits/train/subject_001_session_02__x.csv  \n",
            "  inflating: data/splits/train/subject_001_session_02__y.csv  \n",
            "  inflating: data/splits/train/subject_001_session_06__y.csv  \n",
            "  inflating: data/splits/train/subject_002_session_02__x.csv  \n",
            "  inflating: data/splits/train/subject_002_session_02__y.csv  \n",
            "  inflating: data/splits/train/subject_001_session_06__x.csv  \n",
            "  inflating: data/splits/train/subject_003_session_02__x.csv  \n",
            "  inflating: data/splits/train/subject_003_session_02__y.csv  \n",
            "  inflating: data/splits/train/subject_004_session_01__y.csv  \n",
            "  inflating: data/splits/train/subject_004_session_01__x.csv  \n",
            "  inflating: data/splits/train/subject_002_session_05__x.csv  \n",
            "  inflating: data/splits/train/subject_002_session_05__y.csv  \n",
            "  inflating: data/splits/train/subject_001_session_03__y.csv  \n",
            "  inflating: data/splits/train/subject_005_session_01__y.csv  \n",
            "  inflating: data/splits/train/subject_005_session_01__x.csv  \n",
            "  inflating: data/splits/train/subject_001_session_03__x.csv  \n",
            "  inflating: data/splits/train/subject_001_session_07__x.csv  \n",
            "  inflating: data/splits/train/subject_002_session_03__y.csv  \n",
            "  inflating: data/splits/train/subject_002_session_03__x.csv  \n",
            "  inflating: data/splits/train/subject_001_session_07__y.csv  \n",
            "  inflating: data/splits/train/subject_003_session_01__y.csv  \n",
            "  inflating: data/splits/train/subject_003_session_01__x.csv  \n",
            "  inflating: data/splits/train/subject_003_session_03__y.csv  \n",
            "  inflating: data/splits/train/subject_003_session_03__x.csv  \n",
            "  inflating: data/splits/train/subject_001_session_05__x.csv  \n",
            "  inflating: data/splits/train/subject_001_session_05__y.csv  \n",
            "  inflating: data/splits/val/subject_001_session_04__y.csv  \n",
            "  inflating: data/splits/val/subject_001_session_08__y.csv  \n",
            "  inflating: data/splits/val/subject_001_session_08__x.csv  \n",
            "  inflating: data/splits/val/subject_001_session_04__x.csv  \n",
            "  inflating: data/splits/val/subject_001_session_01__y.csv  \n",
            "  inflating: data/splits/val/subject_001_session_01__x.csv  \n",
            "  inflating: data/splits/val/subject_002_session_01__y.csv  \n",
            "  inflating: data/splits/val/subject_002_session_01__x.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZeuQxwE_NzP"
      },
      "source": [
        "!rm data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uc9PDcigm0u"
      },
      "source": [
        "### Replace [YOUR_ACCESS_TOKEN] with your GitHub access token (remove the brackets)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjjVhlkupOBO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f227a4b6-0e3c-43c2-94a4-55fa28881c75"
      },
      "source": [
        "!git clone https://savadikarc:<ACCESSTOKEN>@github.com/savadikarc/ece542-competition-project.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ece542-competition-project'...\n",
            "remote: Enumerating objects: 224, done.\u001b[K\n",
            "remote: Counting objects: 100% (224/224), done.\u001b[K\n",
            "remote: Compressing objects: 100% (158/158), done.\u001b[K\n",
            "remote: Total 224 (delta 118), reused 150 (delta 56), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (224/224), 273.13 KiB | 1.05 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8yURtFRqGkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd489082-b8ed-4aa0-bd0d-6e682cdbc3d1"
      },
      "source": [
        "!cd ece542-competition-project && git checkout phase-1 && git pull origin phase-1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already on 'phase-1'\n",
            "Your branch is up to date with 'origin/phase-1'.\n",
            "From https://github.com/savadikarc/ece542-competition-project\n",
            " * branch            phase-1    -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJlBSAfPnuG_"
      },
      "source": [
        "base_path = \"/content/drive/MyDrive/ProjC/Nov11_newModel/competition-project-2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kUcwing_Qkz"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append(\"ece542-competition-project\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JxS3qkHmmRB"
      },
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import WeightedRandomSampler\n",
        "import numpy as np\n",
        "from ml_utils.dataset import SubjectDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJCQfTElnJJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "121f2a05-e2a8-4b42-bbcc-608a26cad009"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mKgxfP1mmMg"
      },
      "source": [
        "base_data_path = os.path.join(\"data\", \"splits\")\n",
        "train_data_path = os.path.join(base_data_path, \"train\")\n",
        "val_data_path = os.path.join(base_data_path, \"val\")\n",
        "\n",
        "splits_file = os.path.join(base_path, \"experiments\", \"metadata\", \"split_ids.json\")\n",
        "with open(splits_file, \"r\") as f:\n",
        "    split_ids = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuihFDGQbTBm"
      },
      "source": [
        "stats_path = os.path.join(base_path, \"experiments\", \"metadata\", \"statistics.json\")\n",
        "with open(stats_path, \"r\") as f:\n",
        "    stats = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzQdu4exbfOl"
      },
      "source": [
        "min = np.array([v[\"min\"] for k, v in stats.items()])\n",
        "max = np.array([v[\"max\"] for k, v in stats.items()])\n",
        "\n",
        "min = torch.from_numpy(min).float()\n",
        "min = torch.unsqueeze((torch.unsqueeze(min, 0)), -1)\n",
        "min = min.to(device)\n",
        "max = torch.from_numpy(max).float().to(device)\n",
        "max = torch.unsqueeze((torch.unsqueeze(max, 0)), -1)\n",
        "max = max.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJXYMQrWb-zN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bbb900a-bdd9-4a27-87b3-77a3c644d868"
      },
      "source": [
        "min.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5RT6OvirVrA"
      },
      "source": [
        "# Training hyperparameters\n",
        "batch_size = 128\n",
        "num_epochs = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy47cYBEmmKS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2579c2b8-1221-42d1-9aeb-8f44f2cd2022"
      },
      "source": [
        "train_dataset = SubjectDataset(\n",
        "    train_data_path, \n",
        "    split_ids[\"train\"]\n",
        ")\n",
        "ys = train_dataset.y.tolist()\n",
        "counts = Counter(ys)\n",
        "weights = np.array([1./counts[_y] for _y in ys])\n",
        "sample_weights = torch.from_numpy(weights).float()\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=sample_weights,\n",
        "    num_samples=len(sample_weights),\n",
        "    replacement=True)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
        "train_iterations = (len(train_dataset) // batch_size) + ((len(train_dataset) % batch_size) != 0)\n",
        "\n",
        "val_dataset = SubjectDataset(\n",
        "    val_data_path, \n",
        "    split_ids[\"val\"]\n",
        ")\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_iterations = (len(val_dataset) // batch_size) + ((len(val_dataset) % batch_size) != 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting uid 005_02\n",
            "Converting uid 001_06\n",
            "Converting uid 003_02\n",
            "Converting uid 001_05\n",
            "Converting uid 002_02\n",
            "Converting uid 003_01\n",
            "Converting uid 003_03\n",
            "Converting uid 005_01\n",
            "Converting uid 001_07\n",
            "Converting uid 002_05\n",
            "Converting uid 004_02\n",
            "Converting uid 002_03\n",
            "Converting uid 001_02\n",
            "Converting uid 002_04\n",
            "Converting uid 001_03\n",
            "Converting uid 004_01\n",
            "Converting uid 001_08\n",
            "Converting uid 002_01\n",
            "Converting uid 001_01\n",
            "Converting uid 001_04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4JQ2YWz6JeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28aa7824-f4e7-40f7-9365-cdf5debbf7de"
      },
      "source": [
        "print(train_iterations)\n",
        "print(val_iterations)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1373\n",
            "422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UxWDOBmmmOv"
      },
      "source": [
        "class OneDConvNet(nn.Module):\n",
        "  def __init__(self, n_features, n_classes, base_filters=32):\n",
        "    super(OneDConvNet, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv1d(in_channels=n_features, out_channels=base_filters, kernel_size=3, stride=1, padding=1)\n",
        "    self.norm1 = nn.LayerNorm(base_filters*120)\n",
        "    self.pool1 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
        "    self.conv2 = nn.Conv1d(in_channels=base_filters, out_channels=base_filters*2, kernel_size=3, stride=1, padding=1)\n",
        "    self.norm2 = nn.LayerNorm(base_filters*2*60)\n",
        "    self.pool2 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
        "    self.conv3 = nn.Conv1d(in_channels=base_filters*2, out_channels=base_filters*4, kernel_size=3, stride=1, padding=1)\n",
        "    self.norm3 = nn.LayerNorm(base_filters*4*30)\n",
        "    self.pool3 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
        "    self.conv4 = nn.Conv1d(in_channels=base_filters*4, out_channels=base_filters*8, kernel_size=3, stride=1, padding=1)\n",
        "    self.norm4 = nn.LayerNorm(base_filters*8*15)\n",
        "    self.fc1 = nn.Linear(base_filters*8, base_filters*16)\n",
        "    self.dropout5 = nn.Dropout(0.4)\n",
        "    self.fc2 = nn.Linear(base_filters*16, n_classes)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    N, C, T = x.shape\n",
        "    x = x.view(N, C*T)\n",
        "    x = self.norm1(x)\n",
        "    x = x.view(N, C, T)\n",
        "    x = self.pool1(F.relu(x))\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    N, C, T = x.shape\n",
        "    x = x.view(N, C*T)\n",
        "    x = self.norm2(x)\n",
        "    x = x.view(N, C, T)\n",
        "    x = self.pool2(F.relu(x))\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    N, C, T = x.shape\n",
        "    x = x.view(N, C*T)\n",
        "    x = self.norm3(x)\n",
        "    x = x.view(N, C, T)\n",
        "    x = self.pool3(F.relu(x))\n",
        "\n",
        "    x = self.conv4(x)\n",
        "    N, C, T = x.shape\n",
        "    x = x.view(N, C*T)\n",
        "    x = self.norm4(x)\n",
        "    x = x.view(N, C, T)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    N, C, T = x.size()\n",
        "    x = x.mean(dim=-1) # Flatten\n",
        "    x = self.dropout5(F.relu(self.fc1(x)))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "model = OneDConvNet(6, 4).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7npRJhHxdC1"
      },
      "source": [
        "# import numpy as np\n",
        "# X = np.random.randn(1, 6, 40)\n",
        "# T = torch.from_numpy(X).float().to(device)\n",
        "# y = model(T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sksNpnMfyLOP"
      },
      "source": [
        "# y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSfdHJ4Ry4AG"
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "# optimizer = optim.RMSprop(model.parameters(), lr=1e-3)\n",
        "scheduler = ReduceLROnPlateau(optimizer, factor=0.5, patience=1, verbose=True)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6FBCiBQmmH2"
      },
      "source": [
        "def train_step(X, y, model, optimizer, criterion):\n",
        "\n",
        "    y_pred = model(X)\n",
        "    predicted_classes = torch.argmax(y_pred.detach(), dim=1)\n",
        "\n",
        "    loss = criterion(y_pred, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    corrects = torch.sum(y.data == predicted_classes)\n",
        "\n",
        "    return loss.item(), corrects\n",
        "\n",
        "def val_step(X, y, model, criterion):\n",
        "\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        y_pred = model(X)\n",
        "        predicted_classes = torch.argmax(y_pred.detach(), dim=1)\n",
        "        loss = criterion(y_pred, y)\n",
        "        corrects = torch.sum(y.data == predicted_classes)\n",
        "\n",
        "    return loss.item(), corrects, predicted_classes.detach().cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2K4z1p8mmCQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe357670-21cd-45c3-df8b-debc2053d129"
      },
      "source": [
        "best_val_loss = float(\"inf\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Train for \"n\" number of iterations\n",
        "    running_loss = 0.\n",
        "    running_acc = 0.\n",
        "    for iteration, (X, y) in enumerate(train_dataloader):\n",
        "\n",
        "        X = X.float().to(device)\n",
        "        # Normalize\n",
        "        X = (X - min) / (max - min)\n",
        "\n",
        "        y = y.view(X.size(0)).to(device)\n",
        "\n",
        "        loss, corrects = train_step(X, y, model, optimizer, criterion)\n",
        "\n",
        "        # Running metrics\n",
        "        running_loss = running_loss + loss * X.size(0)\n",
        "        running_acc = running_acc + corrects\n",
        "\n",
        "        if iteration % 100 == 0:\n",
        "            print(f\"Iteration: {iteration}/{train_iterations} | train_loss: {loss} | train_acc: {corrects/X.size(0)}\")\n",
        "\n",
        "    train_loss = running_loss / len(train_dataset)\n",
        "    train_acc = running_acc / len(train_dataset)\n",
        "\n",
        "    # Validate\n",
        "    running_val_loss = 0.\n",
        "    running_val_acc = 0.\n",
        "    for step, (X, y) in enumerate(val_dataloader):\n",
        "\n",
        "        X = X.float().to(device)\n",
        "        X = (X - min) / (max - min)\n",
        "\n",
        "        y = y.view(X.size(0)).to(device)\n",
        "\n",
        "        loss, corrects, predicted_classes = val_step(X, y, model, criterion)\n",
        "        # Running metrics\n",
        "        running_val_loss = running_val_loss + loss * X.size(0)\n",
        "        running_val_acc = running_val_acc + corrects\n",
        "\n",
        "    val_loss = running_val_loss / len(val_dataset)\n",
        "    val_acc = running_val_acc / len(val_dataset)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        # Checkpoint model\n",
        "        path = os.path.join(base_path, \"experiments\", \"models\", \"checkpoint_instance_norm_dropout_sgd_lr3.pth\")\n",
        "        print(f\"Saving model to {path}\")\n",
        "        torch.save(model.state_dict(), path)\n",
        "        best_val_loss = val_loss\n",
        "\n",
        "    print(f\"Epoch: {epoch} | train_loss {train_loss} | train_acc: {train_acc} | val_loss: {val_loss} | val_acc: {val_acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0/1373 | train_loss: 1.3911516666412354 | train_acc: 0.296875\n",
            "Iteration: 100/1373 | train_loss: 1.3998490571975708 | train_acc: 0.265625\n",
            "Iteration: 200/1373 | train_loss: 1.380738377571106 | train_acc: 0.3046875\n",
            "Iteration: 300/1373 | train_loss: 1.3853058815002441 | train_acc: 0.234375\n",
            "Iteration: 400/1373 | train_loss: 1.353224277496338 | train_acc: 0.3515625\n",
            "Iteration: 500/1373 | train_loss: 1.137882113456726 | train_acc: 0.6328125\n",
            "Iteration: 600/1373 | train_loss: 0.8654128909111023 | train_acc: 0.609375\n",
            "Iteration: 700/1373 | train_loss: 0.6415648460388184 | train_acc: 0.6953125\n",
            "Iteration: 800/1373 | train_loss: 0.5866304039955139 | train_acc: 0.6796875\n",
            "Iteration: 900/1373 | train_loss: 0.4559377431869507 | train_acc: 0.828125\n",
            "Iteration: 1000/1373 | train_loss: 0.299166202545166 | train_acc: 0.890625\n",
            "Iteration: 1100/1373 | train_loss: 0.3077176809310913 | train_acc: 0.890625\n",
            "Iteration: 1200/1373 | train_loss: 0.4517780542373657 | train_acc: 0.8125\n",
            "Iteration: 1300/1373 | train_loss: 0.27127084136009216 | train_acc: 0.921875\n",
            "Saving model to /content/drive/MyDrive/ProjC/Nov11_newModel/competition-project-2/experiments/models/checkpoint_instance_norm_dropout_sgd_lr3.pth\n",
            "Epoch: 0 | train_loss 0.815750321692688 | train_acc: 0.6073306202888489 | val_loss: 0.7046940027091719 | val_acc: 0.7156559228897095\n",
            "Iteration: 0/1373 | train_loss: 0.27358347177505493 | train_acc: 0.9453125\n",
            "Iteration: 100/1373 | train_loss: 0.26033666729927063 | train_acc: 0.890625\n",
            "Iteration: 200/1373 | train_loss: 0.2269793152809143 | train_acc: 0.953125\n",
            "Iteration: 300/1373 | train_loss: 0.3056841790676117 | train_acc: 0.8671875\n",
            "Iteration: 400/1373 | train_loss: 0.2919273376464844 | train_acc: 0.8515625\n",
            "Iteration: 500/1373 | train_loss: 0.2622828483581543 | train_acc: 0.90625\n",
            "Iteration: 600/1373 | train_loss: 0.3073277473449707 | train_acc: 0.890625\n",
            "Iteration: 700/1373 | train_loss: 0.20939858257770538 | train_acc: 0.9140625\n",
            "Iteration: 800/1373 | train_loss: 0.2440420240163803 | train_acc: 0.875\n",
            "Iteration: 900/1373 | train_loss: 0.19070248305797577 | train_acc: 0.9296875\n",
            "Iteration: 1000/1373 | train_loss: 0.22755949199199677 | train_acc: 0.921875\n",
            "Iteration: 1100/1373 | train_loss: 0.3130336403846741 | train_acc: 0.8671875\n",
            "Iteration: 1200/1373 | train_loss: 0.1703711301088333 | train_acc: 0.9453125\n",
            "Iteration: 1300/1373 | train_loss: 0.2220783233642578 | train_acc: 0.921875\n",
            "Saving model to /content/drive/MyDrive/ProjC/Nov11_newModel/competition-project-2/experiments/models/checkpoint_instance_norm_dropout_sgd_lr3.pth\n",
            "Epoch: 1 | train_loss 0.206854224571339 | train_acc: 0.9227783679962158 | val_loss: 0.6272893440220734 | val_acc: 0.7638350129127502\n",
            "Iteration: 0/1373 | train_loss: 0.23789013922214508 | train_acc: 0.9140625\n",
            "Iteration: 100/1373 | train_loss: 0.12327199429273605 | train_acc: 0.9609375\n",
            "Iteration: 200/1373 | train_loss: 0.22073988616466522 | train_acc: 0.9140625\n",
            "Iteration: 300/1373 | train_loss: 0.22575438022613525 | train_acc: 0.921875\n",
            "Iteration: 400/1373 | train_loss: 0.16891664266586304 | train_acc: 0.9609375\n",
            "Iteration: 500/1373 | train_loss: 0.1466320902109146 | train_acc: 0.9453125\n",
            "Iteration: 600/1373 | train_loss: 0.11632316559553146 | train_acc: 0.9609375\n",
            "Iteration: 700/1373 | train_loss: 0.13271716237068176 | train_acc: 0.953125\n",
            "Iteration: 800/1373 | train_loss: 0.12240432947874069 | train_acc: 0.96875\n",
            "Iteration: 900/1373 | train_loss: 0.07464170455932617 | train_acc: 0.984375\n",
            "Iteration: 1000/1373 | train_loss: 0.0901222676038742 | train_acc: 0.984375\n",
            "Iteration: 1100/1373 | train_loss: 0.13765428960323334 | train_acc: 0.953125\n",
            "Iteration: 1200/1373 | train_loss: 0.14319735765457153 | train_acc: 0.953125\n",
            "Iteration: 1300/1373 | train_loss: 0.12695226073265076 | train_acc: 0.953125\n",
            "Epoch: 2 | train_loss 0.13837529382198915 | train_acc: 0.95143061876297 | val_loss: 0.8275399513351491 | val_acc: 0.69532310962677\n",
            "Iteration: 0/1373 | train_loss: 0.1253991425037384 | train_acc: 0.9453125\n",
            "Iteration: 100/1373 | train_loss: 0.08423318713903427 | train_acc: 0.96875\n",
            "Iteration: 200/1373 | train_loss: 0.0852232277393341 | train_acc: 0.9765625\n",
            "Iteration: 300/1373 | train_loss: 0.0778898373246193 | train_acc: 0.9765625\n",
            "Iteration: 400/1373 | train_loss: 0.051009729504585266 | train_acc: 0.9921875\n",
            "Iteration: 500/1373 | train_loss: 0.09405405074357986 | train_acc: 0.9765625\n",
            "Iteration: 600/1373 | train_loss: 0.17806142568588257 | train_acc: 0.953125\n",
            "Iteration: 700/1373 | train_loss: 0.17166468501091003 | train_acc: 0.9453125\n",
            "Iteration: 800/1373 | train_loss: 0.10041012614965439 | train_acc: 0.96875\n",
            "Iteration: 900/1373 | train_loss: 0.19173593819141388 | train_acc: 0.9609375\n",
            "Iteration: 1000/1373 | train_loss: 0.08653788268566132 | train_acc: 0.984375\n",
            "Iteration: 1100/1373 | train_loss: 0.12427527457475662 | train_acc: 0.96875\n",
            "Iteration: 1200/1373 | train_loss: 0.11024481803178787 | train_acc: 0.953125\n",
            "Iteration: 1300/1373 | train_loss: 0.0795096829533577 | train_acc: 0.984375\n",
            "Epoch     4: reducing learning rate of group 0 to 5.0000e-04.\n",
            "Epoch: 3 | train_loss 0.11345730679145137 | train_acc: 0.9612412452697754 | val_loss: 0.9432781909935604 | val_acc: 0.7436877489089966\n",
            "Iteration: 0/1373 | train_loss: 0.10320443660020828 | train_acc: 0.953125\n",
            "Iteration: 100/1373 | train_loss: 0.06697332859039307 | train_acc: 0.9765625\n",
            "Iteration: 200/1373 | train_loss: 0.1471841037273407 | train_acc: 0.953125\n",
            "Iteration: 300/1373 | train_loss: 0.09908165037631989 | train_acc: 0.9609375\n",
            "Iteration: 400/1373 | train_loss: 0.05514007806777954 | train_acc: 0.984375\n",
            "Iteration: 500/1373 | train_loss: 0.04120868071913719 | train_acc: 0.9921875\n",
            "Iteration: 600/1373 | train_loss: 0.043489087373018265 | train_acc: 0.984375\n",
            "Iteration: 700/1373 | train_loss: 0.07267709076404572 | train_acc: 0.9609375\n",
            "Iteration: 800/1373 | train_loss: 0.1011740043759346 | train_acc: 0.9765625\n",
            "Iteration: 900/1373 | train_loss: 0.14840376377105713 | train_acc: 0.9453125\n",
            "Iteration: 1000/1373 | train_loss: 0.047100234776735306 | train_acc: 0.9765625\n",
            "Iteration: 1100/1373 | train_loss: 0.04105144739151001 | train_acc: 0.984375\n",
            "Iteration: 1200/1373 | train_loss: 0.035834960639476776 | train_acc: 1.0\n",
            "Iteration: 1300/1373 | train_loss: 0.10931295156478882 | train_acc: 0.9453125\n",
            "Epoch: 4 | train_loss 0.08808958057870764 | train_acc: 0.9705226421356201 | val_loss: 1.0360609153258151 | val_acc: 0.7568224668502808\n",
            "Iteration: 0/1373 | train_loss: 0.028029682114720345 | train_acc: 1.0\n",
            "Iteration: 100/1373 | train_loss: 0.0620705783367157 | train_acc: 0.96875\n",
            "Iteration: 200/1373 | train_loss: 0.07834726572036743 | train_acc: 0.984375\n",
            "Iteration: 300/1373 | train_loss: 0.11155327409505844 | train_acc: 0.9609375\n",
            "Iteration: 400/1373 | train_loss: 0.07269632816314697 | train_acc: 0.96875\n",
            "Iteration: 500/1373 | train_loss: 0.07768436521291733 | train_acc: 0.96875\n",
            "Iteration: 600/1373 | train_loss: 0.047071054577827454 | train_acc: 0.984375\n",
            "Iteration: 700/1373 | train_loss: 0.061414144933223724 | train_acc: 0.9765625\n",
            "Iteration: 800/1373 | train_loss: 0.045566536486148834 | train_acc: 0.984375\n",
            "Iteration: 900/1373 | train_loss: 0.061923835426568985 | train_acc: 0.9765625\n",
            "Iteration: 1000/1373 | train_loss: 0.06935246288776398 | train_acc: 0.984375\n",
            "Iteration: 1100/1373 | train_loss: 0.10821887105703354 | train_acc: 0.96875\n",
            "Iteration: 1200/1373 | train_loss: 0.07141362875699997 | train_acc: 0.984375\n",
            "Iteration: 1300/1373 | train_loss: 0.0504436120390892 | train_acc: 0.9921875\n",
            "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
            "Epoch: 5 | train_loss 0.08238829566442411 | train_acc: 0.9727362990379333 | val_loss: 1.02310024426536 | val_acc: 0.7379181385040283\n",
            "Iteration: 0/1373 | train_loss: 0.03775344416499138 | train_acc: 0.9921875\n",
            "Iteration: 100/1373 | train_loss: 0.07085970044136047 | train_acc: 0.9765625\n",
            "Iteration: 200/1373 | train_loss: 0.07600867003202438 | train_acc: 0.9765625\n",
            "Iteration: 300/1373 | train_loss: 0.10532218217849731 | train_acc: 0.9609375\n",
            "Iteration: 400/1373 | train_loss: 0.06009823828935623 | train_acc: 0.984375\n",
            "Iteration: 500/1373 | train_loss: 0.057073306292295456 | train_acc: 0.9765625\n",
            "Iteration: 600/1373 | train_loss: 0.05568563938140869 | train_acc: 0.984375\n",
            "Iteration: 700/1373 | train_loss: 0.07518485188484192 | train_acc: 0.9765625\n",
            "Iteration: 800/1373 | train_loss: 0.06944061815738678 | train_acc: 0.984375\n",
            "Iteration: 900/1373 | train_loss: 0.07310661673545837 | train_acc: 0.96875\n",
            "Iteration: 1000/1373 | train_loss: 0.10731494426727295 | train_acc: 0.984375\n",
            "Iteration: 1100/1373 | train_loss: 0.06071702018380165 | train_acc: 0.9765625\n",
            "Iteration: 1200/1373 | train_loss: 0.055980850011110306 | train_acc: 0.9765625\n",
            "Iteration: 1300/1373 | train_loss: 0.0670800432562828 | train_acc: 0.9609375\n",
            "Epoch: 6 | train_loss 0.07247897364666561 | train_acc: 0.9760425090789795 | val_loss: 1.136039033014916 | val_acc: 0.7609595060348511\n",
            "Iteration: 0/1373 | train_loss: 0.06481096148490906 | train_acc: 0.984375\n",
            "Iteration: 100/1373 | train_loss: 0.10235560685396194 | train_acc: 0.96875\n",
            "Iteration: 200/1373 | train_loss: 0.04569214582443237 | train_acc: 0.9921875\n",
            "Iteration: 300/1373 | train_loss: 0.02171400375664234 | train_acc: 1.0\n",
            "Iteration: 400/1373 | train_loss: 0.021489383652806282 | train_acc: 0.9921875\n",
            "Iteration: 500/1373 | train_loss: 0.04735153540968895 | train_acc: 0.9765625\n",
            "Iteration: 600/1373 | train_loss: 0.03823158144950867 | train_acc: 0.9921875\n",
            "Iteration: 700/1373 | train_loss: 0.010262466967105865 | train_acc: 1.0\n",
            "Iteration: 800/1373 | train_loss: 0.06478916108608246 | train_acc: 0.9765625\n",
            "Iteration: 900/1373 | train_loss: 0.042083077132701874 | train_acc: 0.9765625\n",
            "Iteration: 1000/1373 | train_loss: 0.02991933934390545 | train_acc: 1.0\n",
            "Iteration: 1100/1373 | train_loss: 0.058902088552713394 | train_acc: 0.984375\n",
            "Iteration: 1200/1373 | train_loss: 0.088730588555336 | train_acc: 0.96875\n",
            "Iteration: 1300/1373 | train_loss: 0.053258396685123444 | train_acc: 0.984375\n",
            "Epoch     8: reducing learning rate of group 0 to 1.2500e-04.\n",
            "Epoch: 7 | train_loss 0.06959466800466078 | train_acc: 0.9765148162841797 | val_loss: 1.0206735961355795 | val_acc: 0.7582694888114929\n",
            "Iteration: 0/1373 | train_loss: 0.08374427258968353 | train_acc: 0.9609375\n",
            "Iteration: 100/1373 | train_loss: 0.019773926585912704 | train_acc: 1.0\n",
            "Iteration: 200/1373 | train_loss: 0.05508146062493324 | train_acc: 0.984375\n",
            "Iteration: 300/1373 | train_loss: 0.05140388011932373 | train_acc: 0.9921875\n",
            "Iteration: 400/1373 | train_loss: 0.0342155285179615 | train_acc: 0.9921875\n",
            "Iteration: 500/1373 | train_loss: 0.033667322248220444 | train_acc: 0.984375\n",
            "Iteration: 600/1373 | train_loss: 0.09771202504634857 | train_acc: 0.9609375\n",
            "Iteration: 700/1373 | train_loss: 0.04373985156416893 | train_acc: 0.984375\n",
            "Iteration: 800/1373 | train_loss: 0.04151860624551773 | train_acc: 0.9921875\n",
            "Iteration: 900/1373 | train_loss: 0.018546955659985542 | train_acc: 1.0\n",
            "Iteration: 1000/1373 | train_loss: 0.05892012268304825 | train_acc: 0.9609375\n",
            "Iteration: 1100/1373 | train_loss: 0.07495250552892685 | train_acc: 0.9765625\n",
            "Iteration: 1200/1373 | train_loss: 0.08019009977579117 | train_acc: 0.984375\n",
            "Iteration: 1300/1373 | train_loss: 0.03344612568616867 | train_acc: 0.9921875\n",
            "Epoch: 8 | train_loss 0.06390784081805277 | train_acc: 0.9794227480888367 | val_loss: 1.0874412482345184 | val_acc: 0.7575274109840393\n",
            "Iteration: 0/1373 | train_loss: 0.042774636298418045 | train_acc: 0.984375\n",
            "Iteration: 100/1373 | train_loss: 0.05148251727223396 | train_acc: 0.9765625\n",
            "Iteration: 200/1373 | train_loss: 0.10168188810348511 | train_acc: 0.9609375\n",
            "Iteration: 300/1373 | train_loss: 0.04766792431473732 | train_acc: 0.96875\n",
            "Iteration: 400/1373 | train_loss: 0.050580233335494995 | train_acc: 0.984375\n",
            "Iteration: 500/1373 | train_loss: 0.035388216376304626 | train_acc: 0.9921875\n",
            "Iteration: 600/1373 | train_loss: 0.0598958358168602 | train_acc: 0.96875\n",
            "Iteration: 700/1373 | train_loss: 0.10642265528440475 | train_acc: 0.9765625\n",
            "Iteration: 800/1373 | train_loss: 0.025890594348311424 | train_acc: 0.9921875\n",
            "Iteration: 900/1373 | train_loss: 0.07441870123147964 | train_acc: 0.9609375\n",
            "Iteration: 1000/1373 | train_loss: 0.05889410525560379 | train_acc: 0.9765625\n",
            "Iteration: 1100/1373 | train_loss: 0.055858537554740906 | train_acc: 0.9765625\n",
            "Iteration: 1200/1373 | train_loss: 0.08883943408727646 | train_acc: 0.9765625\n",
            "Iteration: 1300/1373 | train_loss: 0.09959675371646881 | train_acc: 0.9609375\n",
            "Epoch    10: reducing learning rate of group 0 to 6.2500e-05.\n",
            "Epoch: 9 | train_loss 0.061940047549404194 | train_acc: 0.9799235463142395 | val_loss: 1.0867280718869028 | val_acc: 0.7476021647453308\n",
            "Iteration: 0/1373 | train_loss: 0.10911587625741959 | train_acc: 0.96875\n",
            "Iteration: 100/1373 | train_loss: 0.031076055020093918 | train_acc: 0.9921875\n",
            "Iteration: 200/1373 | train_loss: 0.07560037821531296 | train_acc: 0.984375\n",
            "Iteration: 300/1373 | train_loss: 0.06566107273101807 | train_acc: 0.984375\n",
            "Iteration: 400/1373 | train_loss: 0.0663754791021347 | train_acc: 0.96875\n",
            "Iteration: 500/1373 | train_loss: 0.01684376783668995 | train_acc: 1.0\n",
            "Iteration: 600/1373 | train_loss: 0.05459018796682358 | train_acc: 0.984375\n",
            "Iteration: 700/1373 | train_loss: 0.10623804479837418 | train_acc: 0.9609375\n",
            "Iteration: 800/1373 | train_loss: 0.03780011087656021 | train_acc: 0.984375\n",
            "Iteration: 900/1373 | train_loss: 0.028491495177149773 | train_acc: 1.0\n",
            "Iteration: 1000/1373 | train_loss: 0.08956734836101532 | train_acc: 0.9609375\n",
            "Iteration: 1100/1373 | train_loss: 0.020476825535297394 | train_acc: 1.0\n",
            "Iteration: 1200/1373 | train_loss: 0.03870593011379242 | train_acc: 0.9921875\n",
            "Iteration: 1300/1373 | train_loss: 0.07179538905620575 | train_acc: 0.984375\n",
            "Epoch: 10 | train_loss 0.06108620599964397 | train_acc: 0.9804641008377075 | val_loss: 1.1315823038155175 | val_acc: 0.756859540939331\n",
            "Iteration: 0/1373 | train_loss: 0.02727826125919819 | train_acc: 0.9921875\n",
            "Iteration: 100/1373 | train_loss: 0.07540048658847809 | train_acc: 0.96875\n",
            "Iteration: 200/1373 | train_loss: 0.046606503427028656 | train_acc: 0.9765625\n",
            "Iteration: 300/1373 | train_loss: 0.12384536117315292 | train_acc: 0.96875\n",
            "Iteration: 400/1373 | train_loss: 0.0352151095867157 | train_acc: 0.9765625\n",
            "Iteration: 500/1373 | train_loss: 0.13635225594043732 | train_acc: 0.953125\n",
            "Iteration: 600/1373 | train_loss: 0.03652893006801605 | train_acc: 0.9921875\n",
            "Iteration: 700/1373 | train_loss: 0.09551756083965302 | train_acc: 0.96875\n",
            "Iteration: 800/1373 | train_loss: 0.041470881551504135 | train_acc: 0.984375\n",
            "Iteration: 900/1373 | train_loss: 0.07450318336486816 | train_acc: 0.9609375\n",
            "Iteration: 1000/1373 | train_loss: 0.06292138993740082 | train_acc: 0.9921875\n",
            "Iteration: 1100/1373 | train_loss: 0.028166964650154114 | train_acc: 0.9921875\n",
            "Iteration: 1200/1373 | train_loss: 0.050851523876190186 | train_acc: 0.984375\n",
            "Iteration: 1300/1373 | train_loss: 0.13496018946170807 | train_acc: 0.96875\n",
            "Epoch    12: reducing learning rate of group 0 to 3.1250e-05.\n",
            "Epoch: 11 | train_loss 0.05856651604751507 | train_acc: 0.9812323451042175 | val_loss: 1.1227938973691125 | val_acc: 0.7483813762664795\n",
            "Iteration: 0/1373 | train_loss: 0.05903099477291107 | train_acc: 0.9765625\n",
            "Iteration: 100/1373 | train_loss: 0.04740326851606369 | train_acc: 0.984375\n",
            "Iteration: 200/1373 | train_loss: 0.07487276941537857 | train_acc: 0.984375\n",
            "Iteration: 300/1373 | train_loss: 0.12004275619983673 | train_acc: 0.96875\n",
            "Iteration: 400/1373 | train_loss: 0.05442366376519203 | train_acc: 0.9765625\n",
            "Iteration: 500/1373 | train_loss: 0.08102069795131683 | train_acc: 0.96875\n",
            "Iteration: 600/1373 | train_loss: 0.041067518293857574 | train_acc: 0.984375\n",
            "Iteration: 700/1373 | train_loss: 0.08907494693994522 | train_acc: 0.9609375\n",
            "Iteration: 800/1373 | train_loss: 0.029034370556473732 | train_acc: 0.9921875\n",
            "Iteration: 900/1373 | train_loss: 0.06966704875230789 | train_acc: 0.984375\n",
            "Iteration: 1000/1373 | train_loss: 0.09987623244524002 | train_acc: 0.96875\n",
            "Iteration: 1100/1373 | train_loss: 0.14629396796226501 | train_acc: 0.953125\n",
            "Iteration: 1200/1373 | train_loss: 0.03399774804711342 | train_acc: 0.9921875\n",
            "Iteration: 1300/1373 | train_loss: 0.05710972100496292 | train_acc: 0.984375\n",
            "Epoch: 12 | train_loss 0.05735922113826157 | train_acc: 0.9817445278167725 | val_loss: 1.1371138156584932 | val_acc: 0.7566183805465698\n",
            "Iteration: 0/1373 | train_loss: 0.06547967344522476 | train_acc: 0.9609375\n",
            "Iteration: 100/1373 | train_loss: 0.12485361099243164 | train_acc: 0.9765625\n",
            "Iteration: 200/1373 | train_loss: 0.050338830798864365 | train_acc: 0.96875\n",
            "Iteration: 300/1373 | train_loss: 0.04097582772374153 | train_acc: 0.9921875\n",
            "Iteration: 400/1373 | train_loss: 0.1269889622926712 | train_acc: 0.96875\n",
            "Iteration: 500/1373 | train_loss: 0.030666077509522438 | train_acc: 0.984375\n",
            "Iteration: 600/1373 | train_loss: 0.09974952042102814 | train_acc: 0.9609375\n",
            "Iteration: 700/1373 | train_loss: 0.026713019236922264 | train_acc: 1.0\n",
            "Iteration: 800/1373 | train_loss: 0.04729677736759186 | train_acc: 0.984375\n",
            "Iteration: 900/1373 | train_loss: 0.04008986055850983 | train_acc: 0.9765625\n",
            "Iteration: 1000/1373 | train_loss: 0.033981215208768845 | train_acc: 0.984375\n",
            "Iteration: 1100/1373 | train_loss: 0.06328807771205902 | train_acc: 0.9765625\n",
            "Iteration: 1200/1373 | train_loss: 0.062298696488142014 | train_acc: 0.9765625\n",
            "Iteration: 1300/1373 | train_loss: 0.030466368421912193 | train_acc: 0.9921875\n",
            "Epoch    14: reducing learning rate of group 0 to 1.5625e-05.\n",
            "Epoch: 13 | train_loss 0.05606466980820106 | train_acc: 0.9821940660476685 | val_loss: 1.1424795884054415 | val_acc: 0.7560617923736572\n",
            "Iteration: 0/1373 | train_loss: 0.0755431056022644 | train_acc: 0.9765625\n",
            "Iteration: 100/1373 | train_loss: 0.03801677003502846 | train_acc: 0.984375\n",
            "Iteration: 200/1373 | train_loss: 0.03639700636267662 | train_acc: 0.984375\n",
            "Iteration: 300/1373 | train_loss: 0.060182057321071625 | train_acc: 0.9765625\n",
            "Iteration: 400/1373 | train_loss: 0.06642647087574005 | train_acc: 0.9765625\n",
            "Iteration: 500/1373 | train_loss: 0.03628702461719513 | train_acc: 1.0\n",
            "Iteration: 600/1373 | train_loss: 0.08120657503604889 | train_acc: 0.96875\n",
            "Iteration: 700/1373 | train_loss: 0.03275367245078087 | train_acc: 0.9921875\n",
            "Iteration: 800/1373 | train_loss: 0.11619417369365692 | train_acc: 0.9609375\n",
            "Iteration: 900/1373 | train_loss: 0.09797027707099915 | train_acc: 0.9765625\n",
            "Iteration: 1000/1373 | train_loss: 0.039554938673973083 | train_acc: 0.9921875\n",
            "Iteration: 1100/1373 | train_loss: 0.056418802589178085 | train_acc: 0.984375\n",
            "Iteration: 1200/1373 | train_loss: 0.08977404981851578 | train_acc: 0.9609375\n",
            "Iteration: 1300/1373 | train_loss: 0.02725215256214142 | train_acc: 1.0\n",
            "Epoch: 14 | train_loss 0.05617043902251408 | train_acc: 0.9819835424423218 | val_loss: 1.1447492749288994 | val_acc: 0.7550414800643921\n",
            "Iteration: 0/1373 | train_loss: 0.02222040854394436 | train_acc: 1.0\n",
            "Iteration: 100/1373 | train_loss: 0.08311624825000763 | train_acc: 0.9765625\n",
            "Iteration: 200/1373 | train_loss: 0.017574593424797058 | train_acc: 1.0\n",
            "Iteration: 300/1373 | train_loss: 0.08983822911977768 | train_acc: 0.9609375\n",
            "Iteration: 400/1373 | train_loss: 0.04557250812649727 | train_acc: 0.984375\n",
            "Iteration: 500/1373 | train_loss: 0.02989206463098526 | train_acc: 0.9921875\n",
            "Iteration: 600/1373 | train_loss: 0.032941825687885284 | train_acc: 0.9921875\n",
            "Iteration: 700/1373 | train_loss: 0.028018368408083916 | train_acc: 1.0\n",
            "Iteration: 800/1373 | train_loss: 0.03103790618479252 | train_acc: 0.9921875\n",
            "Iteration: 900/1373 | train_loss: 0.07722879946231842 | train_acc: 0.984375\n",
            "Iteration: 1000/1373 | train_loss: 0.03875148668885231 | train_acc: 0.984375\n",
            "Iteration: 1100/1373 | train_loss: 0.018085885792970657 | train_acc: 0.9921875\n",
            "Iteration: 1200/1373 | train_loss: 0.03152477368712425 | train_acc: 1.0\n",
            "Iteration: 1300/1373 | train_loss: 0.02113589458167553 | train_acc: 0.9921875\n",
            "Epoch    16: reducing learning rate of group 0 to 7.8125e-06.\n",
            "Epoch: 15 | train_loss 0.055639664811003915 | train_acc: 0.9827574491500854 | val_loss: 1.170062089511296 | val_acc: 0.7545776963233948\n",
            "Iteration: 0/1373 | train_loss: 0.056553278118371964 | train_acc: 0.984375\n",
            "Iteration: 100/1373 | train_loss: 0.06679940223693848 | train_acc: 0.96875\n",
            "Iteration: 200/1373 | train_loss: 0.04715100675821304 | train_acc: 0.9765625\n",
            "Iteration: 300/1373 | train_loss: 0.12756387889385223 | train_acc: 0.96875\n",
            "Iteration: 400/1373 | train_loss: 0.018524067476391792 | train_acc: 1.0\n",
            "Iteration: 500/1373 | train_loss: 0.07396729290485382 | train_acc: 0.984375\n",
            "Iteration: 600/1373 | train_loss: 0.0390661247074604 | train_acc: 0.9921875\n",
            "Iteration: 700/1373 | train_loss: 0.0287639033049345 | train_acc: 0.9921875\n",
            "Iteration: 800/1373 | train_loss: 0.030753804370760918 | train_acc: 0.9921875\n",
            "Iteration: 900/1373 | train_loss: 0.048977043479681015 | train_acc: 0.9765625\n",
            "Iteration: 1000/1373 | train_loss: 0.06123463809490204 | train_acc: 0.984375\n",
            "Iteration: 1100/1373 | train_loss: 0.026840541511774063 | train_acc: 0.9921875\n",
            "Iteration: 1200/1373 | train_loss: 0.06356360018253326 | train_acc: 0.984375\n",
            "Iteration: 1300/1373 | train_loss: 0.05387438088655472 | train_acc: 0.96875\n",
            "Epoch: 16 | train_loss 0.054898506690837325 | train_acc: 0.982620894908905 | val_loss: 1.1382303620933736 | val_acc: 0.7534274458885193\n",
            "Iteration: 0/1373 | train_loss: 0.03011457435786724 | train_acc: 0.9921875\n",
            "Iteration: 100/1373 | train_loss: 0.037214137613773346 | train_acc: 0.9765625\n",
            "Iteration: 200/1373 | train_loss: 0.025207150727510452 | train_acc: 0.9921875\n",
            "Iteration: 300/1373 | train_loss: 0.044513653963804245 | train_acc: 0.9921875\n",
            "Iteration: 400/1373 | train_loss: 0.02831018529832363 | train_acc: 0.984375\n",
            "Iteration: 500/1373 | train_loss: 0.04455380141735077 | train_acc: 0.9921875\n",
            "Iteration: 600/1373 | train_loss: 0.04380545765161514 | train_acc: 0.984375\n",
            "Iteration: 700/1373 | train_loss: 0.05928633362054825 | train_acc: 0.9765625\n",
            "Iteration: 800/1373 | train_loss: 0.032082345336675644 | train_acc: 0.9921875\n",
            "Iteration: 900/1373 | train_loss: 0.028572184965014458 | train_acc: 0.9921875\n",
            "Iteration: 1000/1373 | train_loss: 0.024755794554948807 | train_acc: 0.9921875\n",
            "Iteration: 1100/1373 | train_loss: 0.013140007853507996 | train_acc: 1.0\n",
            "Iteration: 1200/1373 | train_loss: 0.027175333350896835 | train_acc: 1.0\n",
            "Iteration: 1300/1373 | train_loss: 0.08623077720403671 | train_acc: 0.953125\n",
            "Epoch    18: reducing learning rate of group 0 to 3.9063e-06.\n",
            "Epoch: 17 | train_loss 0.05402814076290309 | train_acc: 0.9834972023963928 | val_loss: 1.1618432369990386 | val_acc: 0.7514795064926147\n",
            "Iteration: 0/1373 | train_loss: 0.028201844543218613 | train_acc: 0.9921875\n",
            "Iteration: 100/1373 | train_loss: 0.04915471374988556 | train_acc: 0.9765625\n",
            "Iteration: 200/1373 | train_loss: 0.137806698679924 | train_acc: 0.953125\n",
            "Iteration: 300/1373 | train_loss: 0.0384952649474144 | train_acc: 0.9921875\n",
            "Iteration: 400/1373 | train_loss: 0.0349813736975193 | train_acc: 1.0\n",
            "Iteration: 500/1373 | train_loss: 0.02999281696975231 | train_acc: 0.9921875\n",
            "Iteration: 600/1373 | train_loss: 0.11215366423130035 | train_acc: 0.9609375\n",
            "Iteration: 700/1373 | train_loss: 0.04656219854950905 | train_acc: 0.984375\n",
            "Iteration: 800/1373 | train_loss: 0.07870130240917206 | train_acc: 0.984375\n",
            "Iteration: 900/1373 | train_loss: 0.08302342146635056 | train_acc: 0.984375\n",
            "Iteration: 1000/1373 | train_loss: 0.0582757294178009 | train_acc: 0.9921875\n",
            "Iteration: 1100/1373 | train_loss: 0.11593814939260483 | train_acc: 0.9765625\n",
            "Iteration: 1200/1373 | train_loss: 0.05661924555897713 | train_acc: 0.9765625\n",
            "Iteration: 1300/1373 | train_loss: 0.04874637350440025 | train_acc: 0.984375\n",
            "Epoch: 18 | train_loss 0.05525920683773969 | train_acc: 0.9828940033912659 | val_loss: 1.1520753255207226 | val_acc: 0.7525926232337952\n",
            "Iteration: 0/1373 | train_loss: 0.05739990249276161 | train_acc: 0.9765625\n",
            "Iteration: 100/1373 | train_loss: 0.0837441012263298 | train_acc: 0.9609375\n",
            "Iteration: 200/1373 | train_loss: 0.05450858920812607 | train_acc: 0.96875\n",
            "Iteration: 300/1373 | train_loss: 0.023673569783568382 | train_acc: 0.9921875\n",
            "Iteration: 400/1373 | train_loss: 0.02962331287562847 | train_acc: 1.0\n",
            "Iteration: 500/1373 | train_loss: 0.04196172207593918 | train_acc: 0.984375\n",
            "Iteration: 600/1373 | train_loss: 0.059658072888851166 | train_acc: 0.9609375\n",
            "Iteration: 700/1373 | train_loss: 0.06618937849998474 | train_acc: 0.96875\n",
            "Iteration: 800/1373 | train_loss: 0.04655395820736885 | train_acc: 0.984375\n",
            "Iteration: 900/1373 | train_loss: 0.023581089451909065 | train_acc: 1.0\n",
            "Iteration: 1000/1373 | train_loss: 0.03597636520862579 | train_acc: 0.984375\n",
            "Iteration: 1100/1373 | train_loss: 0.07556407153606415 | train_acc: 0.96875\n",
            "Iteration: 1200/1373 | train_loss: 0.07044412195682526 | train_acc: 0.9921875\n",
            "Iteration: 1300/1373 | train_loss: 0.055668905377388 | train_acc: 0.9765625\n",
            "Epoch    20: reducing learning rate of group 0 to 1.9531e-06.\n",
            "Epoch: 19 | train_loss 0.05543080408224141 | train_acc: 0.9826151728630066 | val_loss: 1.1563919448130247 | val_acc: 0.7550785541534424\n",
            "Iteration: 0/1373 | train_loss: 0.06775829195976257 | train_acc: 0.9609375\n",
            "Iteration: 100/1373 | train_loss: 0.0771893635392189 | train_acc: 0.984375\n",
            "Iteration: 200/1373 | train_loss: 0.03569537028670311 | train_acc: 0.984375\n",
            "Iteration: 300/1373 | train_loss: 0.0847061276435852 | train_acc: 0.9765625\n",
            "Iteration: 400/1373 | train_loss: 0.02151348814368248 | train_acc: 0.9921875\n",
            "Iteration: 500/1373 | train_loss: 0.057124312967061996 | train_acc: 0.9921875\n",
            "Iteration: 600/1373 | train_loss: 0.07926233857870102 | train_acc: 0.9921875\n",
            "Iteration: 700/1373 | train_loss: 0.07663168013095856 | train_acc: 0.9765625\n",
            "Iteration: 800/1373 | train_loss: 0.030255960300564766 | train_acc: 0.9921875\n",
            "Iteration: 900/1373 | train_loss: 0.018569497391581535 | train_acc: 1.0\n",
            "Iteration: 1000/1373 | train_loss: 0.02366659790277481 | train_acc: 0.9921875\n",
            "Iteration: 1100/1373 | train_loss: 0.047864850610494614 | train_acc: 0.9765625\n",
            "Iteration: 1200/1373 | train_loss: 0.10102418810129166 | train_acc: 0.984375\n",
            "Iteration: 1300/1373 | train_loss: 0.017160022631287575 | train_acc: 1.0\n",
            "Epoch: 20 | train_loss 0.05499780294343356 | train_acc: 0.9826720952987671 | val_loss: 1.1541233795315224 | val_acc: 0.7532975673675537\n",
            "Iteration: 0/1373 | train_loss: 0.1062145009636879 | train_acc: 0.9609375\n",
            "Iteration: 100/1373 | train_loss: 0.11965340375900269 | train_acc: 0.953125\n",
            "Iteration: 200/1373 | train_loss: 0.0392591692507267 | train_acc: 0.9921875\n",
            "Iteration: 300/1373 | train_loss: 0.09771924465894699 | train_acc: 0.953125\n",
            "Iteration: 400/1373 | train_loss: 0.09225217252969742 | train_acc: 0.96875\n",
            "Iteration: 500/1373 | train_loss: 0.03423555567860603 | train_acc: 0.984375\n",
            "Iteration: 600/1373 | train_loss: 0.04800347238779068 | train_acc: 0.984375\n",
            "Iteration: 700/1373 | train_loss: 0.11574508249759674 | train_acc: 0.984375\n",
            "Iteration: 800/1373 | train_loss: 0.046069275587797165 | train_acc: 0.984375\n",
            "Iteration: 900/1373 | train_loss: 0.06063801050186157 | train_acc: 0.9921875\n",
            "Iteration: 1000/1373 | train_loss: 0.06793705374002457 | train_acc: 0.96875\n",
            "Iteration: 1100/1373 | train_loss: 0.03407241031527519 | train_acc: 0.9921875\n",
            "Iteration: 1200/1373 | train_loss: 0.08068503439426422 | train_acc: 0.9765625\n",
            "Iteration: 1300/1373 | train_loss: 0.025580205023288727 | train_acc: 1.0\n",
            "Epoch    22: reducing learning rate of group 0 to 9.7656e-07.\n",
            "Epoch: 21 | train_loss 0.0563189821331529 | train_acc: 0.9826720952987671 | val_loss: 1.1529731660422824 | val_acc: 0.7540211081504822\n",
            "Iteration: 0/1373 | train_loss: 0.05979800596833229 | train_acc: 0.984375\n",
            "Iteration: 100/1373 | train_loss: 0.03415742889046669 | train_acc: 0.984375\n",
            "Iteration: 200/1373 | train_loss: 0.06097274646162987 | train_acc: 0.9765625\n",
            "Iteration: 300/1373 | train_loss: 0.07287247478961945 | train_acc: 0.984375\n",
            "Iteration: 400/1373 | train_loss: 0.023638788610696793 | train_acc: 0.984375\n",
            "Iteration: 500/1373 | train_loss: 0.01888810470700264 | train_acc: 1.0\n",
            "Iteration: 600/1373 | train_loss: 0.022192474454641342 | train_acc: 0.9921875\n",
            "Iteration: 700/1373 | train_loss: 0.07475197315216064 | train_acc: 0.9765625\n",
            "Iteration: 800/1373 | train_loss: 0.0725238099694252 | train_acc: 0.9765625\n",
            "Iteration: 900/1373 | train_loss: 0.054570272564888 | train_acc: 0.984375\n",
            "Iteration: 1000/1373 | train_loss: 0.08247758448123932 | train_acc: 0.984375\n",
            "Iteration: 1100/1373 | train_loss: 0.07651668041944504 | train_acc: 0.984375\n",
            "Iteration: 1200/1373 | train_loss: 0.032344840466976166 | train_acc: 1.0\n",
            "Iteration: 1300/1373 | train_loss: 0.078094981610775 | train_acc: 0.984375\n",
            "Epoch: 22 | train_loss 0.05392418400034529 | train_acc: 0.9828200340270996 | val_loss: 1.1475817826382415 | val_acc: 0.7533717751502991\n",
            "Iteration: 0/1373 | train_loss: 0.03716977313160896 | train_acc: 0.9921875\n",
            "Iteration: 100/1373 | train_loss: 0.082939013838768 | train_acc: 0.9609375\n",
            "Iteration: 200/1373 | train_loss: 0.09155184775590897 | train_acc: 0.9609375\n",
            "Iteration: 300/1373 | train_loss: 0.043612245470285416 | train_acc: 0.984375\n",
            "Iteration: 400/1373 | train_loss: 0.07908594608306885 | train_acc: 0.984375\n",
            "Iteration: 500/1373 | train_loss: 0.025726500898599625 | train_acc: 0.9921875\n",
            "Iteration: 600/1373 | train_loss: 0.03431784734129906 | train_acc: 0.9765625\n",
            "Iteration: 700/1373 | train_loss: 0.10441238433122635 | train_acc: 0.96875\n",
            "Iteration: 800/1373 | train_loss: 0.09790617972612381 | train_acc: 0.96875\n",
            "Iteration: 900/1373 | train_loss: 0.020618494600057602 | train_acc: 0.9921875\n",
            "Iteration: 1000/1373 | train_loss: 0.040886830538511276 | train_acc: 0.984375\n",
            "Iteration: 1100/1373 | train_loss: 0.04164581745862961 | train_acc: 0.9921875\n",
            "Iteration: 1200/1373 | train_loss: 0.026627469807863235 | train_acc: 1.0\n",
            "Iteration: 1300/1373 | train_loss: 0.046881016343832016 | train_acc: 0.984375\n",
            "Epoch    24: reducing learning rate of group 0 to 4.8828e-07.\n",
            "Epoch: 23 | train_loss 0.05415740208283947 | train_acc: 0.9833436012268066 | val_loss: 1.1509859902034754 | val_acc: 0.7530935406684875\n",
            "Iteration: 0/1373 | train_loss: 0.04842551797628403 | train_acc: 0.96875\n",
            "Iteration: 100/1373 | train_loss: 0.015150478109717369 | train_acc: 1.0\n",
            "Iteration: 200/1373 | train_loss: 0.10812332481145859 | train_acc: 0.953125\n",
            "Iteration: 300/1373 | train_loss: 0.026917606592178345 | train_acc: 0.984375\n",
            "Iteration: 400/1373 | train_loss: 0.07809369266033173 | train_acc: 0.984375\n",
            "Iteration: 500/1373 | train_loss: 0.027037974447011948 | train_acc: 0.9921875\n",
            "Iteration: 600/1373 | train_loss: 0.1072709709405899 | train_acc: 0.9765625\n",
            "Iteration: 700/1373 | train_loss: 0.16254641115665436 | train_acc: 0.9453125\n",
            "Iteration: 800/1373 | train_loss: 0.0670328438282013 | train_acc: 0.9765625\n",
            "Iteration: 900/1373 | train_loss: 0.03357021510601044 | train_acc: 0.9921875\n",
            "Iteration: 1000/1373 | train_loss: 0.05914590507745743 | train_acc: 0.96875\n",
            "Iteration: 1100/1373 | train_loss: 0.04712074622511864 | train_acc: 0.984375\n",
            "Iteration: 1200/1373 | train_loss: 0.027286265045404434 | train_acc: 0.9921875\n",
            "Iteration: 1300/1373 | train_loss: 0.042431578040122986 | train_acc: 0.984375\n",
            "Epoch: 24 | train_loss 0.05514137535679485 | train_acc: 0.9827346801757812 | val_loss: 1.147400239550147 | val_acc: 0.7528709173202515\n",
            "Iteration: 0/1373 | train_loss: 0.02521839551627636 | train_acc: 0.9921875\n",
            "Iteration: 100/1373 | train_loss: 0.11919515579938889 | train_acc: 0.9609375\n",
            "Iteration: 200/1373 | train_loss: 0.0491572767496109 | train_acc: 0.96875\n",
            "Iteration: 300/1373 | train_loss: 0.04915931448340416 | train_acc: 0.9609375\n",
            "Iteration: 400/1373 | train_loss: 0.1232653558254242 | train_acc: 0.96875\n",
            "Iteration: 500/1373 | train_loss: 0.07168412953615189 | train_acc: 0.9765625\n",
            "Iteration: 600/1373 | train_loss: 0.021202171221375465 | train_acc: 0.9921875\n",
            "Iteration: 700/1373 | train_loss: 0.060205332934856415 | train_acc: 0.984375\n",
            "Iteration: 800/1373 | train_loss: 0.04379856213927269 | train_acc: 0.9921875\n",
            "Iteration: 900/1373 | train_loss: 0.038606978952884674 | train_acc: 0.9765625\n",
            "Iteration: 1000/1373 | train_loss: 0.01688147336244583 | train_acc: 0.9921875\n",
            "Iteration: 1100/1373 | train_loss: 0.0732429176568985 | train_acc: 0.984375\n",
            "Iteration: 1200/1373 | train_loss: 0.04580746963620186 | train_acc: 0.984375\n",
            "Iteration: 1300/1373 | train_loss: 0.0546826608479023 | train_acc: 0.984375\n",
            "Epoch    26: reducing learning rate of group 0 to 2.4414e-07.\n",
            "Epoch: 25 | train_loss 0.054629040306560725 | train_acc: 0.9832525253295898 | val_loss: 1.1540997696328008 | val_acc: 0.7537057399749756\n",
            "Iteration: 0/1373 | train_loss: 0.031830448657274246 | train_acc: 0.9921875\n",
            "Iteration: 100/1373 | train_loss: 0.029680568724870682 | train_acc: 1.0\n",
            "Iteration: 200/1373 | train_loss: 0.0858924463391304 | train_acc: 0.9765625\n",
            "Iteration: 300/1373 | train_loss: 0.07884199917316437 | train_acc: 0.96875\n",
            "Iteration: 400/1373 | train_loss: 0.05037115886807442 | train_acc: 0.9765625\n",
            "Iteration: 500/1373 | train_loss: 0.07187791913747787 | train_acc: 0.96875\n",
            "Iteration: 600/1373 | train_loss: 0.06897756457328796 | train_acc: 0.984375\n",
            "Iteration: 700/1373 | train_loss: 0.050414010882377625 | train_acc: 0.96875\n",
            "Iteration: 800/1373 | train_loss: 0.06862194836139679 | train_acc: 0.9765625\n",
            "Iteration: 900/1373 | train_loss: 0.023475877940654755 | train_acc: 0.9921875\n",
            "Iteration: 1000/1373 | train_loss: 0.032102297991514206 | train_acc: 1.0\n",
            "Iteration: 1100/1373 | train_loss: 0.024262797087430954 | train_acc: 0.9921875\n",
            "Iteration: 1200/1373 | train_loss: 0.023015031591057777 | train_acc: 0.9921875\n",
            "Iteration: 1300/1373 | train_loss: 0.07545726746320724 | train_acc: 0.9765625\n",
            "Epoch: 26 | train_loss 0.05409220519324616 | train_acc: 0.9834631085395813 | val_loss: 1.1519425981547189 | val_acc: 0.7536315321922302\n",
            "Iteration: 0/1373 | train_loss: 0.10054130852222443 | train_acc: 0.9609375\n",
            "Iteration: 100/1373 | train_loss: 0.014385795220732689 | train_acc: 1.0\n",
            "Iteration: 200/1373 | train_loss: 0.04401683062314987 | train_acc: 0.984375\n",
            "Iteration: 300/1373 | train_loss: 0.07922852784395218 | train_acc: 0.9765625\n",
            "Iteration: 400/1373 | train_loss: 0.0839148759841919 | train_acc: 0.9765625\n",
            "Iteration: 500/1373 | train_loss: 0.04903059080243111 | train_acc: 0.984375\n",
            "Iteration: 600/1373 | train_loss: 0.03179941698908806 | train_acc: 0.9765625\n",
            "Iteration: 700/1373 | train_loss: 0.04267245531082153 | train_acc: 0.984375\n",
            "Iteration: 800/1373 | train_loss: 0.04604123905301094 | train_acc: 0.984375\n",
            "Iteration: 900/1373 | train_loss: 0.1251094937324524 | train_acc: 0.9765625\n",
            "Iteration: 1000/1373 | train_loss: 0.035998132079839706 | train_acc: 0.9921875\n",
            "Iteration: 1100/1373 | train_loss: 0.09295882284641266 | train_acc: 0.96875\n",
            "Iteration: 1200/1373 | train_loss: 0.08996446430683136 | train_acc: 0.9609375\n",
            "Iteration: 1300/1373 | train_loss: 0.03087044693529606 | train_acc: 0.9921875\n",
            "Epoch    28: reducing learning rate of group 0 to 1.2207e-07.\n",
            "Epoch: 27 | train_loss 0.05513784888160692 | train_acc: 0.98295658826828 | val_loss: 1.1487761347147405 | val_acc: 0.753149151802063\n",
            "Iteration: 0/1373 | train_loss: 0.031271982938051224 | train_acc: 0.984375\n",
            "Iteration: 100/1373 | train_loss: 0.04313824698328972 | train_acc: 0.984375\n",
            "Iteration: 200/1373 | train_loss: 0.04759722948074341 | train_acc: 0.984375\n",
            "Iteration: 300/1373 | train_loss: 0.09576980769634247 | train_acc: 0.96875\n",
            "Iteration: 400/1373 | train_loss: 0.06454852223396301 | train_acc: 0.96875\n",
            "Iteration: 500/1373 | train_loss: 0.04062825068831444 | train_acc: 0.984375\n",
            "Iteration: 600/1373 | train_loss: 0.05123467370867729 | train_acc: 0.984375\n",
            "Iteration: 700/1373 | train_loss: 0.02543642744421959 | train_acc: 0.9921875\n",
            "Iteration: 800/1373 | train_loss: 0.041707843542099 | train_acc: 0.9921875\n",
            "Iteration: 900/1373 | train_loss: 0.05739657208323479 | train_acc: 0.984375\n",
            "Iteration: 1000/1373 | train_loss: 0.03313537687063217 | train_acc: 0.9921875\n",
            "Iteration: 1100/1373 | train_loss: 0.028994563966989517 | train_acc: 0.9921875\n",
            "Iteration: 1200/1373 | train_loss: 0.11209482699632645 | train_acc: 0.9765625\n",
            "Iteration: 1300/1373 | train_loss: 0.058178868144750595 | train_acc: 0.984375\n",
            "Epoch: 28 | train_loss 0.05330818617326536 | train_acc: 0.983468770980835 | val_loss: 1.1507234087132427 | val_acc: 0.7539098262786865\n",
            "Iteration: 0/1373 | train_loss: 0.07583548873662949 | train_acc: 0.96875\n",
            "Iteration: 100/1373 | train_loss: 0.02682718262076378 | train_acc: 0.9921875\n",
            "Iteration: 200/1373 | train_loss: 0.047094423323869705 | train_acc: 0.984375\n",
            "Iteration: 300/1373 | train_loss: 0.05018759146332741 | train_acc: 0.984375\n",
            "Iteration: 400/1373 | train_loss: 0.04319402202963829 | train_acc: 0.984375\n",
            "Iteration: 500/1373 | train_loss: 0.06155380979180336 | train_acc: 0.96875\n",
            "Iteration: 600/1373 | train_loss: 0.04133991524577141 | train_acc: 0.984375\n",
            "Iteration: 700/1373 | train_loss: 0.10131820291280746 | train_acc: 0.96875\n",
            "Iteration: 800/1373 | train_loss: 0.09353750199079514 | train_acc: 0.96875\n",
            "Iteration: 900/1373 | train_loss: 0.017891885712742805 | train_acc: 0.9921875\n",
            "Iteration: 1000/1373 | train_loss: 0.07167991995811462 | train_acc: 0.9765625\n",
            "Iteration: 1100/1373 | train_loss: 0.028413984924554825 | train_acc: 1.0\n",
            "Iteration: 1300/1373 | train_loss: 0.027326002717018127 | train_acc: 0.9921875\n",
            "Epoch    30: reducing learning rate of group 0 to 6.1035e-08.\n",
            "Epoch: 29 | train_loss 0.05364014913774786 | train_acc: 0.983275294303894 | val_loss: 1.1489288357041367 | val_acc: 0.7537614107131958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9_ZITbCybTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02a06ba4-8214-4a26-fd66-27dd921cdcde"
      },
      "source": [
        "np.array([train_dataset.y[0]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7g8J7WadLvm"
      },
      "source": [
        "best_model = OneDConvNet(6, 4)\n",
        "best_model.load_state_dict(torch.load(os.path.join(base_path, \"experiments\", \"models\", \"checkpoint_instance_norm_dropout_sgd_lr3.pth\")))\n",
        "best_model = best_model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK-nLeloml-n"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "class Evaluation:\n",
        "\n",
        "  def __init__(self):\n",
        "        pass\n",
        "  \n",
        "  def aggregate_metrics(self, y, y_hat):\n",
        "    \n",
        "    \"\"\" Metrics for entire set \n",
        "        \n",
        "        Arguments passed are: \n",
        "                      y     : ground truth  \n",
        "                      y_hat : predicted class\n",
        "        Calculations:\n",
        "                  accuracy  : (tp + tn) / (total samples =(p + n))\n",
        "                  precision : tp / (tp + fp)\n",
        "                  recall    : tp / (tp + fn)\n",
        "                  f1        : 2 tp / (2 tp + fp + fn)\n",
        "    \"\"\"\n",
        "    accuracy  = accuracy_score(y, y_hat)\n",
        "    precision = precision_score(y, y_hat, average=\"macro\")\n",
        "    recall    = recall_score(y, y_hat, average=\"macro\")\n",
        "    f1        = f1_score(y, y_hat, average=\"macro\")\n",
        "    return {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1\": f1\n",
        "        }\n",
        "\n",
        "  def classwise_metrics(self, y, y_hat):\n",
        "\n",
        "    \"\"\" Metrics for each class. \n",
        "        Average is set to macro for calculating the score of each label, and find their unweighted mean. \n",
        "        This does not take label imbalance into account.\n",
        "        \n",
        "        Arguments passed are: \n",
        "                      y     : ground truth  \n",
        "                      y_hat : predicted class\n",
        "        Calculations:\n",
        "                  accuracy  : (tp + tn) / (total samples =(p + n))\n",
        "                  precision : tp / (tp + fp)\n",
        "                  recall    : tp / (tp + fn)\n",
        "                  f1        : 2 tp / (2 tp + fp + fn)\n",
        "    \"\"\"\n",
        "    \n",
        "    class_precision = precision_score(y, y_hat, average=None)\n",
        "    class_recall    = recall_score(y, y_hat, average=None)\n",
        "    class_f1        = f1_score(y, y_hat, average=None)\n",
        "    \n",
        "    return {\n",
        "        \"Precision\": class_precision,\n",
        "        \"Recall\": class_recall,\n",
        "        \"F1\": class_f1\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvN9WtxwznFw"
      },
      "source": [
        "evaluator = Evaluation()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYbdv_EDml8M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4322ed07-261b-42e9-8e10-fb6a6720372c"
      },
      "source": [
        "val_dataset = SubjectDataset(\n",
        "    val_data_path, \n",
        "    split_ids[\"val\"]\n",
        ")\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "val_iterations = (len(val_dataset) // batch_size) + ((len(val_dataset) % batch_size) != 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting uid 001_08\n",
            "Converting uid 002_01\n",
            "Converting uid 001_01\n",
            "Converting uid 001_04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qvZJ2dCxb-H"
      },
      "source": [
        "output = []\n",
        "labels = []\n",
        "for X, y in val_dataloader:\n",
        "    X = X.float().to(device)\n",
        "    X = (X - min) / (max - min)\n",
        "    \n",
        "    y = y.view(X.size(0)).to(device)\n",
        "\n",
        "    y_pred = best_model(X)\n",
        "    predicted_classes = torch.argmax(y_pred, dim=1).detach().cpu().numpy()\n",
        "    y_true = y.cpu().numpy()\n",
        "\n",
        "    output.append(predicted_classes)\n",
        "    labels.append(y_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8p4RTYs0CuR"
      },
      "source": [
        "_output = np.concatenate(output, axis=0)\n",
        "_labels = np.concatenate(labels, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EI4HBWhS0Gao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2996fe87-a9ea-4841-83d1-2d78041ec0f9"
      },
      "source": [
        "agg_metrics = evaluator.aggregate_metrics(_labels, _output)\n",
        "print(\"Agg metrics\")\n",
        "print(agg_metrics)\n",
        "classwise_metrics = evaluator.classwise_metrics(_labels, _output)\n",
        "print(\"Classwise Metrics\")\n",
        "print(classwise_metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agg metrics\n",
            "{'Accuracy': 0.7639648999128064, 'Precision': 0.6943457689547142, 'Recall': 0.7868069815256803, 'F1': 0.7205357624804392}\n",
            "Classwise Metrics\n",
            "{'Precision': array([0.81415544, 0.71512247, 0.55896928, 0.68913589]), 'Recall': array([0.84257381, 0.91081723, 0.9297725 , 0.46406439]), 'F1': array([0.82812089, 0.80119314, 0.69819262, 0.5546364 ])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UosykPCA0GX_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e5bf8c3-c0a2-4749-e149-737034cfcc5a"
      },
      "source": [
        "test_data_path = os.path.join(base_data_path, \"test\")\n",
        "test_dataset = SubjectDataset(\n",
        "    test_data_path, \n",
        "    split_ids[\"test\"]\n",
        ")\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_iterations = (len(test_dataset) // batch_size) + ((len(test_dataset) % batch_size) != 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting uid 005_03\n",
            "Converting uid 006_01\n",
            "Converting uid 006_02\n",
            "Converting uid 006_03\n",
            "Converting uid 007_01\n",
            "Converting uid 007_02\n",
            "Converting uid 007_03\n",
            "Converting uid 007_04\n",
            "Converting uid 008_01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV5m259v4D5L"
      },
      "source": [
        "output = []\n",
        "labels = []\n",
        "for X, y in test_dataloader:\n",
        "    X = X.float().to(device)\n",
        "    X = (X - min) / (max - min)\n",
        "    \n",
        "    y = y.view(X.size(0)).to(device)\n",
        "\n",
        "    y_pred = best_model(X)\n",
        "    predicted_classes = torch.argmax(y_pred, dim=1).detach().cpu().numpy()\n",
        "    y_true = y.cpu().numpy()\n",
        "\n",
        "    output.append(predicted_classes)\n",
        "    labels.append(y_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDB40FUf4TY8"
      },
      "source": [
        "_output = np.concatenate(output, axis=0)\n",
        "_labels = np.concatenate(labels, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtmDpRBH4XDQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "585086be-a00c-4314-86cf-eb65023c8931"
      },
      "source": [
        "agg_metrics = evaluator.aggregate_metrics(_labels, _output)\n",
        "print(\"Agg metrics\")\n",
        "print(agg_metrics)\n",
        "classwise_metrics = evaluator.classwise_metrics(_labels, _output)\n",
        "print(\"Classwise Metrics\")\n",
        "print(classwise_metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agg metrics\n",
            "{'Accuracy': 0.9183509481764384, 'Precision': 0.8324434549092692, 'Recall': 0.9222066561031865, 'F1': 0.872718448091402}\n",
            "Classwise Metrics\n",
            "{'Precision': array([0.96535883, 0.74620445, 0.83529412, 0.78291642]), 'Recall': array([0.93114962, 0.94914709, 0.96978477, 0.83874515]), 'F1': array([0.94794569, 0.83552911, 0.89752921, 0.80986978])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMx7IIGjpyNZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8273e096-6e36-47e4-81dd-b840a4a099c4"
      },
      "source": [
        "path = os.path.join(base_path, \"experiments\", \"models\", \"checkpoint_instance_norm_dropout_sgd_lr3_long.pth\")\n",
        "print(f\"Saving model to {path}\")\n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to /content/drive/MyDrive/ProjC/Nov11_newModel/competition-project-2/experiments/models/checkpoint_instance_norm_dropout_sgd_lr3_long.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZISb6yI1ewr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
